<h1 align="center">âš¡ Swift OCR âš¡</h1>
<h3 align="center">Stop squinting at PDFs. Start extracting clean markdown.</h3>

<p align="center">
  <strong>
    <em>The LLM-powered OCR engine that turns any PDF into beautifully formatted Markdown. It reads your documents like a human, handles messy layouts, and outputs text your AI can actually understand.</em>
  </strong>
</p>

<p align="center">
  <!-- Package Info -->
  <a href="#"><img alt="python" src="https://img.shields.io/badge/python-3.8+-4D87E6.svg?style=flat-square"></a>
  <a href="#"><img alt="fastapi" src="https://img.shields.io/badge/FastAPI-0.100+-4D87E6.svg?style=flat-square"></a>
  &nbsp;&nbsp;â€¢&nbsp;&nbsp;
  <!-- Features -->
  <a href="https://www.gnu.org/licenses/agpl-3.0"><img alt="license" src="https://img.shields.io/badge/License-AGPL_v3-F9A825.svg?style=flat-square"></a>
  <a href="#"><img alt="platform" src="https://img.shields.io/badge/platform-macOS_|_Linux_|_Windows-2ED573.svg?style=flat-square"></a>
</p>

<p align="center">
  <img alt="gpt-4/5 vision" src="https://img.shields.io/badge/ğŸ§ _GPT--4/5_Vision-powered_by_OpenAI-2ED573.svg?style=for-the-badge">
  <img alt="markdown output" src="https://img.shields.io/badge/ğŸ“_markdown_output-tables,_headers,_lists-2ED573.svg?style=for-the-badge">
</p>

<div align="center">

### ğŸ§­ Quick Navigation

[**âš¡ Get Started**](#-get-started-in-60-seconds) â€¢
[**âœ¨ Key Features**](#-feature-breakdown-the-secret-sauce) â€¢
[**ğŸ® Usage & Examples**](#-usage-fire-and-forget) â€¢
[**ğŸ’° Cost Breakdown**](#-cost-breakdown-stupidly-cheap) â€¢
[**âš™ï¸ Configuration**](#ï¸-configuration) â€¢
[**ğŸ—ï¸ Project Structure**](#ï¸-project-structure)

</div>

---

**Swift OCR** is the document processor your AI assistant wishes it had. Stop feeding your LLM screenshots and praying it reads them correctly. This tool acts like a professional transcriber, reading every page of your PDF, intelligently handling tables, headers, and mixed layouts, then packaging everything into perfectly structured Markdown so your AI can actually work with it.

<div align="center">
<table>
<tr>
<td align="center">
<h3>ğŸ§ </h3>
<b>GPT-4 Vision</b><br/>
<sub>Human-level reading accuracy</sub>
</td>
<td align="center">
<h3>âš¡</h3>
<b>Parallel Processing</b><br/>
<sub>Multi-page PDFs in seconds</sub>
</td>
<td align="center">
<h3>ğŸ“</h3>
<b>Clean Markdown</b><br/>
<sub>Tables, headers, listsâ€”all formatted</sub>
</td>
</tr>
</table>
</div>

How it slaps:
- **You:** `curl -X POST "http://localhost:8000/ocr" -F "file=@messy_document.pdf"`
- **Swift OCR:** Converts pages â†’ Sends to GPT-4 Vision â†’ Formats as Markdown
- **You:** Get perfectly structured text with tables, headers, and lists intact.
- **Result:** Your AI finally understands that 50-page contract. â˜•

---

## ğŸ“¹ Demo

https://github.com/user-attachments/assets/6b39f3ea-248e-4c29-ac2e-b57de64d5d65

*Demo video showcasing the conversion of NASA's Apollo 17 flight documentsâ€”complete with unorganized, horizontally and vertically oriented pagesâ€”into well-structured Markdown format without breaking a sweat.*

---

## ğŸ’¥ Why This Slaps Other Methods

Manually extracting text from PDFs is a vibe-killer. Swift OCR makes traditional OCR look ancient.

<table align="center">
<tr>
<td align="center"><b>âŒ The Old Way (Pain)</b></td>
<td align="center"><b>âœ… The Swift OCR Way (Glory)</b></td>
</tr>
<tr>
<td>
<ol>
  <li>Run Tesseract. Get garbled text.</li>
  <li>Tables? What tables? Just random words now.</li>
  <li>Manually fix formatting for 2 hours.</li>
  <li>Feed broken context to your AI.</li>
  <li>Get a useless answer. Cry.</li>
</ol>
</td>
<td>
<ol>
  <li>Upload PDF to Swift OCR.</li>
  <li>Get perfectly formatted Markdown.</li>
  <li>Tables intact. Headers preserved.</li>
  <li>Feed clean context to your AI.</li>
  <li>Get genius-level answers. Go grab a coffee. â˜•</li>
</ol>
</td>
</tr>
</table>

We're not just running basic OCR. We're using **GPT-4 Vision** to actually *understand* your documentsâ€”handling rotated pages, complex tables, mixed layouts, and even describing images for accessibility.

---

## ğŸ’° Cost Breakdown: Stupidly Cheap

Our solution offers an optimal balance of affordability and accuracy that makes enterprise OCR solutions look like highway robbery.

<div align="center">

| Metric | Value |
|:------:|:------|
| **Avg tokens/page** | ~1,500 (including prompt) |
| **GPT-4o input cost** | $5 per million tokens |
| **GPT-4o output cost** | $15 per million tokens |
| **Cost per 1,000 pages** | **~$15** |

</div>

### ğŸ’¡ Want It Even Cheaper?

| Optimization | Cost per 1,000 pages |
|:------------:|:--------------------:|
| **GPT-4o (default)** | ~$15 |
| **GPT-4o mini** | ~$8 |
| **Batch API** | ~$4 |

### ğŸ†š Market Comparison

<div align="center">

| Solution | Cost per 1,000 pages | Tables? | Markdown? |
|:--------:|:-------------------:|:-------:|:---------:|
| **Swift OCR** | **$15** | âœ… Perfect | âœ… Native |
| CloudConvert (PDFTron) | ~$30 | âš ï¸ Basic | âŒ No |
| Adobe Acrobat API | ~$50+ | âœ… Good | âŒ No |
| Tesseract (free) | $0 | âŒ Broken | âŒ No |

</div>

> **Bottom line:** Half the cost of competitors, 10x the quality. It's not just about being cheaperâ€”it's about getting output you can actually use.

---

## ğŸš€ Get Started in 60 Seconds

### Prerequisites

- **Python 3.8+**
- **Azure OpenAI** account (with GPT-4 Vision deployment)

### Installation

```bash
# Clone the repo
git clone https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown.git
cd swift-ocr-llm-powered-pdf-to-markdown

# Create virtual environment (recommended)
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configure Environment

Create a `.env` file in the root directory:

```env
# Required
OPENAI_API_KEY=your_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
OPENAI_DEPLOYMENT_ID=your_gpt4_vision_deployment

# Optional (sensible defaults)
OPENAI_API_VERSION=gpt-4o
BATCH_SIZE=1                        # Images per OCR request (1-10)
MAX_CONCURRENT_OCR_REQUESTS=5       # Parallel OCR calls
MAX_CONCURRENT_PDF_CONVERSION=4     # Parallel page rendering
```

### Run It

```bash
# Option 1: Classic uvicorn (backward compatible)
uvicorn main:app --reload

# Option 2: Using the new package
uvicorn swift_ocr.app:app --reload

# Option 3: As a Python module
python -m swift_ocr

# Option 4: With CLI arguments
python -m swift_ocr --host 0.0.0.0 --port 8080 --workers 4
```

ğŸ‰ **API is now live at `http://127.0.0.1:8000`**

> **âœ¨ Pro tip:** Check out the auto-generated docs at `http://127.0.0.1:8000/docs`

---

## ğŸ® Usage: Fire and Forget

### API Endpoint

**POST** `/ocr`

Accept a PDF file upload OR a URL to a PDF. Returns beautifully formatted Markdown.

### Examples

**Upload a PDF file:**

```bash
curl -X POST "http://127.0.0.1:8000/ocr" \
  -F "file=@/path/to/your/document.pdf"
```

**Process a PDF from URL:**

```bash
curl -X POST "http://127.0.0.1:8000/ocr" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/document.pdf"}'
```

### Response

```json
{
  "text": "# Document Title\n\n## Section 1\n\nExtracted text with **formatting** preserved...\n\n| Column 1 | Column 2 |\n|----------|----------|\n| Data     | Data     |"
}
```

### Response (v2.0+)

The new response includes additional metadata:

```json
{
  "text": "# Document Title\n\n## Section 1\n\nExtracted text...",
  "status": "success",
  "pages_processed": 5,
  "processing_time_ms": 1234
}
```

### Health Check

```bash
curl http://127.0.0.1:8000/health
```

```json
{
  "status": "healthy",
  "version": "2.0.0",
  "timestamp": "2024-01-01T00:00:00Z",
  "openai_configured": true
}
```

### Error Codes

| Code | Meaning |
|:----:|:--------|
| `200` | Successâ€”Markdown text returned |
| `400` | Bad request (no file/URL, or both provided) |
| `422` | Validation error |
| `429` | Rate limitedâ€”retry with backoff |
| `500` | Processing error |
| `504` | Timeout downloading PDF |

---

## âœ¨ Feature Breakdown: The Secret Sauce

<div align="center">

| Feature | What It Does | Why You Care |
| :---: | :--- | :--- |
| **ğŸ§  GPT-4 Vision**<br/>`Human-level OCR` | Uses OpenAI's most capable vision model to read documents | Actually understands context, not just character shapes |
| **âš¡ Parallel Processing**<br/>`Multiprocessing + async` | Converts PDF pages and calls OCR in parallel | 50-page PDF in seconds, not minutes |
| **ğŸ“Š Table Preservation**<br/>`Markdown tables` | Detects and formats tables as proper Markdown | Your data stays structured, not flattened to gibberish |
| **ğŸ”„ Smart Batching**<br/>`Configurable batch size` | Groups pages to optimize API calls vs accuracy | Balance speed and cost for your use case |
| **ğŸ›¡ï¸ Retry with Backoff**<br/>`Exponential backoff` | Automatically retries on rate limits and timeouts | Handles API hiccups without crashing |
| **ğŸ“„ Flexible Input**<br/>`File upload or URL` | Accept PDFs directly or fetch from any URL | Works with your existing workflow |
| **ğŸ–¼ï¸ Image Descriptions**<br/>`Accessibility-friendly` | Describes non-text elements: `[Image: description]` | Context your AI can actually use |

</div>

---

## âš™ï¸ Configuration

All settings are managed via environment variables. Tune these for your workload:

<div align="center">

| Variable | Default | Description |
|:---------|:-------:|:------------|
| `OPENAI_API_KEY` | â€” | Your Azure OpenAI API key |
| `AZURE_OPENAI_ENDPOINT` | â€” | Your Azure OpenAI endpoint URL |
| `OPENAI_DEPLOYMENT_ID` | â€” | Your GPT-4 Vision deployment ID |
| `OPENAI_API_VERSION` | `gpt-4o` | API version |
| `BATCH_SIZE` | `1` | Pages per OCR request (1-10). Higher = faster but less accurate |
| `MAX_CONCURRENT_OCR_REQUESTS` | `5` | Parallel OCR calls. Increase for throughput |
| `MAX_CONCURRENT_PDF_CONVERSION` | `4` | Parallel page renders. Match your CPU cores |

</div>

### Performance Tuning Tips

- **High accuracy, slower:** `BATCH_SIZE=1`
- **Balanced:** `BATCH_SIZE=5`, `MAX_CONCURRENT_OCR_REQUESTS=10`
- **Maximum throughput:** `BATCH_SIZE=10`, `MAX_CONCURRENT_OCR_REQUESTS=20` (watch rate limits!)

---

## ğŸ—ï¸ Project Structure

World-class Python engineering with atomic modules and clean separation of concerns:

```
swift_ocr/
â”œâ”€â”€ __init__.py              # Package init with version
â”œâ”€â”€ __main__.py              # CLI entry point (python -m swift_ocr)
â”œâ”€â”€ app.py                   # FastAPI app factory
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py          # Pydantic Settings (type-safe config)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ exceptions.py        # Custom exception hierarchy
â”‚   â”œâ”€â”€ logging.py           # Structured logging setup
â”‚   â””â”€â”€ retry.py             # Exponential backoff utilities
â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ocr.py               # Pydantic request/response models
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ocr.py               # OpenAI Vision OCR service
â”‚   â””â”€â”€ pdf.py               # PDF conversion service
â””â”€â”€ api/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ deps.py              # Dependency injection
    â”œâ”€â”€ exceptions.py        # FastAPI exception handlers
    â”œâ”€â”€ router.py            # Route aggregation
    â””â”€â”€ routes/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ health.py        # Health check endpoints
        â””â”€â”€ ocr.py           # OCR endpoints
```

<details>
<summary><b>Key architectural decisions</b></summary>

| Pattern | Implementation | Benefit |
| :--- | :--- | :--- |
| **Pydantic Settings** | `config/settings.py` | Type-safe config with `.env` support and validation |
| **Dependency Injection** | `api/deps.py` | Testable, swappable services |
| **Custom Exceptions** | `core/exceptions.py` | Rich error context with proper HTTP status codes |
| **Retry with Backoff** | `core/retry.py` | Handles rate limits and transient failures |
| **App Factory** | `app.py` | Configurable app creation for testing |
| **Typed Throughout** | `py.typed` marker | Full mypy compatibility |

</details>

---

## ğŸ”¥ Common Issues & Quick Fixes

<details>
<summary><b>Expand for troubleshooting tips</b></summary>

| Problem | Solution |
| :--- | :--- |
| **"Missing required environment variables"** | Check your `.env` file has all three required variables: `OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `OPENAI_DEPLOYMENT_ID` |
| **Rate limit errors (429)** | Reduce `MAX_CONCURRENT_OCR_REQUESTS` or `BATCH_SIZE`. The retry logic will handle temporary limits automatically. |
| **Timeout errors** | Large PDFs take time. The system has exponential backoff built inâ€”give it a moment. |
| **Garbled output** | Make sure your PDF isn't password-protected or corrupted. Try opening it locally first. |
| **Tables not formatting correctly** | Some extremely complex tables may need `BATCH_SIZE=1` for best accuracy. |
| **"Failed to initialize OpenAI client"** | Verify your Azure endpoint URL format: `https://your-resource.openai.azure.com/` |

</details>

---

## ğŸ“œ License

This project uses **PyMuPDF** for PDF processing, which requires the **GNU AGPL v3.0** license.

> **Want MIT instead?** Fork this project and swap PyMuPDF for `pdf2image` + Poppler. The rest of the code is yours to use freely.

```
GNU AFFERO GENERAL PUBLIC LICENSE
Version 3, 19 November 2007

Copyright (C) 2024 YiÄŸit Konur
```

See [LICENSE.md](LICENSE.md) for the full license text.

---

<div align="center">

**Built with ğŸ”¥ because manually transcribing PDFs is a soul-crushing waste of time.**

[Report Bug](https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown/issues) â€¢
[Request Feature](https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown/issues)

</div>
